training:
  num_total_clients: 1
  epoch_per_round: 1
  data_per_speaker: 10
  speaker_per_client: 462
  batch_size: 10
  num_workers: 8
  accumulate_grad_batches: 7


validation:
  batch_size: 8
  num_workers: 8

augment:
  freq_mask: 3
  time_mask: 8

model:
  optim:
    type: SGD
    initial_lr: 0.00005 # 5e-5
    sched:
      type: "none"

